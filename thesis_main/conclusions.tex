%%% The last chapter containing the outline of conclusions, some discussion points and directions for future research
\section{Conclusions}

In the context of a factorial experiment and fitting a polynomial regression model we explored ways of incorporating the possibility of model misspecification in compound optimality criteria and developed methodology for their practical implementation.

In Chapter \ref{ch::compound} we started by investigating some modifications to the criteria introduced by \cite{GilmourTrinca2012} that were suggested in the discussion of the paper. The first one, including an F-quantile, would guarantee enough degrees of freedom for both inference and testing for the model lack of fit purposes; however, this single component does not seem to be interpretable enough. The second is to consider desirability functions of the elementary criteria as components of the compound criteria; such an approach might certainly be of particular interest. We would suggest building the parameterisations of the desirability functions for any specific experiment individually in order to tune the importance of each component's impact according to the particular experimental objectives.

Looking for a more interpretable approach to tackling the potential presence of model contamination, we appealed to the generalised optimality criteria developed by \cite{Goos2005model} and modified them from the view point of `pure error' based inference, which is model-independent and hence is the most sensible one in such a framework. The new generalised $DP$ and $LP$ criteria (as presented in Chapter \ref{ch::generalised} for both unblocked and blocked experiments) contain components which are `responsible' for the minimisation of the primary and posterior potential terms' variances and minimisation of the predicted bias. We explored a few illustrative examples showing how the resulting designs' performances and structures respond to various weight allocations, how strong the contradictions are between the components corresponding to the primary and potential terms and how they are affected by the value of the tuning parameter $\tau^2$. Whilst most of the designs are highly or moderately efficient in terms of the component criteria corresponding to the primary model inference, the performance with respect to the lack-of-fit and bias can be quite sensitive to any amendments in both weight allocations and the parameters of the prior distribution. 

In Chapter \ref{ch::mse} we considered the bias of the estimators of the fitted model's coefficients (instead of the prediction bias), and this lead to the derivation of the component criteria based on the mean square error matrix, which we combined together with the primary terms and lack-of-fit components from the previously derived criteria. The determinant-based criterion turned out to be computationally more demanding, so we suggested an alternative way of evaluating the mean square error component which involves putting a point prior on the potential terms instead of the normal prior. It was shown to provide reasonably good results in the examples we explored. These compound criteria were also adapted for the framework of blocked experiments (Chapter \ref{ch::mse_blocked}), and an example of a real-life experiment was investigated in detail, which allowed demonstrating the applicability of the developed methodology to the demands and restrictions of a particular experiment. We slightly adapted the search algorithm and presented a set of solutions, from which the final design was chosen; it was later used in the experiment, and some useful conclusions have been drawn from the gathered data.

The final piece of work presented in this thesis is devoted to the optimal planning for multistratum experiments, where due to various restrictions experimental units are organised into hierarchical nested structures; we adapted the mean square error based criteria for this setting, and presented the flexible implementation of the design search algorithm. A few demonstrative examples were used to explore the characteristics of the constructed optimal designs and provided insights for the potential applications (as in Chapter \ref{ch::mse_ms}). Some of the recommendations, that are also relevant for other criteria and experimental outlines, would be to choose the weight allocation scheme according to the priorities of the experimenters, and, if possible, to consider a set of optimal designs prior to making the final choice.

\section{Some Directions for Future Work}

In the course of this work we considered determinant- and trace-based criteria (i.e. $D$- and $L$-optimality); however, other criteria, for example, $I$-optimality (for average prediction variance), or $E$-optimality (minimising the maximum of the estimators' variances) might be evolved in order to account for a potential model misspecification. The MSE-based criteria could be adapted to operate with the subset of the parameters of interest, i.e. so that a submatrix of the mean square matrix is to be researched.

As for combining several elementary criteria in one, a possible alternative could be using the Pareto frontier approach (described in detail, for example, in \cite{Lu2011optimization}), which would allow making the choice after having observed the best designs in terms of several criteria and not by choosing the weight combination for the compound criteria first. On one hand, such an algorithm would result in a set of designs, such that each of them would outperform every other in terms of at least one component criterion; on the other hand --- firstly, in a case of more than three elementary criteria and larger experiments, it would require a considerable amount of computational resources and, secondly, in its original setup, it would not allow for any way of exploring the relationships between the individual criteria components.

Another approach that might be worth considering is maximising the minimum efficiency among the efficiencies in terms of the component criteria; however, a small decrease in the performance with respect to one of the components may result in a larger increase in others.

The need for an \textit{a priori} specified model contamination form and the prior distribution parameters may become a non-straightforward problem, especially if not much is known about the process under study. Besides, it requires some additional effort at the stage of implementation: for every experimental layout the candidate set of potential terms is to be manually set up. Various ideas of introducing randomness when describing model contamination were evolved by \cite{Notz1989Optimal} and later by \cite{Allen2003Experimental} and \cite{Woods2005designing} (as mentioned in Section \ref{sec::back_misspecification}); it would be of interest to incorporate the effect of model misspecification presented in a probabilistic form in the inference optimality criteria. 

In this work we considered unblocked, blocked and simple nested structures of experimental units. However, an interesting extension would be to expand the MSE-based criteria to crossed structures and more complicated setups. For example, the experimental frameworks where the treatment-unit additivity assumption does not necessarily hold (e.g.~optimal design on networks) and ones with complex interventions are of growing importance and it would be useful to conduct methodological research for such structures. 

