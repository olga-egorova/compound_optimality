Standard design optimality theory is developed under the assumption that the fitted model represents the true relationship of interest and that there is no misspecification. However, it is obviously quite a strong belief and in reality we need to take into account at least the possibility that the model might not provide a good fit to the data. 
%In Section \ref{sec::back_misspecification} a brief overview of various types of model misspecification is presented. 
?? Other types of model misspecification (in background)

In this chapter we consider the case when the fitted polynomial model is nested within a larger model that is assumed to provide a better fit for the data:
\begin{equation}
\label{eq::full_model}
\bm{Y}=\bm{X}_1\bm{\beta}_1+\bm{X}_2\bm{\beta}_2+\bm{\varepsilon},
\end{equation}
where $\bm{X}_2$ is an $n\times q$ is an extension of the initial model matrix representing those extra $q$ potential terms that might represent the fitted model disturbance. The vector $\bm{\beta}_2$ denotes the corresponding parameters. This larger model has $p+q$ parameters in total and not all of them are estimable when the experiment is relatively small: $n<p+q$; this is the case we consider here.
\subsection{Lack-of-fit criterion}
%We consider the Generalised criterion presented by Goos et al.: [more details?]
%\begin{equation*}
%\mbox{minimise }|\bm{X}'_{1}\bm{X}_1|^{-\frac{\kappa_{D}}{p}}\times \left|\bm{L}+\frac{\bm{I}_{q}}{\tau^{2}}\right|^{-\frac{\kappa_{LoF}}{q}} \times |\bm{A}'\bm{A}+\bm{I}_{q}|.^{\frac{\kappa_{bias}}{q}},
%\end{equation*}
%where $\bm{L}$ is known in literature as dispersion matrix, and the matrix $\bm{L}+\bm{I}_{q}/\tau^{2}$ in the second component is essentially the inverse posterior variance-covariance matrix of the vector of potential terms (up to a factor of $\sigma^2$).

 ** Derivation first or the Generalised criterion

To be able to control the scope of the potential terms, we adapt Bayesian approach:  diffuse prior shall be put on primary terms (as was done by \cite{DuMouchel1994}) -- an arbitrary mean and a variance going to infinity, and the prior on potential terms is a normal distribution: $\bm{\beta}_2\sim\mathcal{N}(0,\bm{\Sigma}_{0})$, with the prior variance scaled with respect to the error variation:
$\bm{\Sigma}_{0}=\sigma^{2}\tau^{2}\bm{I}_{q}$. Then the posterior
distribution of the coefficients is (as in \cite{Koch2007introduction} and \cite{DuMouchel1994}):
$$\bm{\beta}|\bm{Y}\sim \mathcal{N}(\bm{b},\bm{\Sigma}),\mbox{ where }\bm{b}=\bm{\Sigma X}'\bm{Y}, \bm{X}=[\bm{X}_1, \bm{X}_2],$$
$$\bm{\Sigma}=\left[\frac{\bm{K}}{\sigma^{2}\tau^{2}}+\sigma^{-2}(\bm{X'X})\right]^{-1}=\sigma^{2}[\bm{K}/\tau^{2}+\bm{X'}\bm{X}],^{-1}$$
and 
\begin{equation*}
\bm{K}=\begin{pmatrix}
\bm{0}_{p\times p} & \bm{0}_{p\times q}\\
\bm{0}_{q\times p} & \bm{I}_{q\times q}
\end{pmatrix}.
\end{equation*}
The marginal posterior of $\bm{\beta}_2$ is $\mathcal{N}(\bm{b}_{2},\bm{\Sigma}_{22})$, so using the general formula for the inverse of a block matrix
$$\begin{bmatrix}
 \bm{A}& \bm{B}\\
 \bm{C}& \bm{D}
\end{bmatrix}^{-1}=\begin{bmatrix}
\ldots & \ldots\\
\ldots & (\bm{D}-\bm{CA}^{-1}\bm{B})^{-1}
\end{bmatrix},$$
we can obtain the expression for $\bm{\Sigma}_{22}$:
\begin{align*}
[\bm{K}/\tau^{2}+\bm{X}'\bm{X}]^{-1}&=\begin{bmatrix}
 \bm{X}'_1\bm{X}_1& \bm{X}'_1\bm{X}_2 \\
 \bm{X}'_2\bm{X}_1& \bm{X}'_2\bm{X}_2+\bm{I}_{q}/\tau^{2}
\end{bmatrix}^{-1}\\&=\begin{bmatrix}
\ldots & \ldots\\
\ldots &
(\bm{X}'_2\bm{X}_2+\bm{I}_{q}/\tau^{2}-\bm{X}'_2\bm{X}_1(\bm{X}'_1\bm{X}_1)^{-1}\bm{X}'_1\bm{X}_2)^{-1}
\end{bmatrix},\\
\bm{\Sigma}_{22}&=\sigma^{2}[(\bm{K}/\tau^{2}+\bm{X}^{'}\bm{X})^{-1}]_{22}=\sigma^{2}\left(\bm{L}+\frac{\bm{I}_{q}}{\tau^{2}}\right)^{-1},
\end{align*} 
and $$(\bm{\Sigma}_{22})^{-1}=\frac{1}{\sigma^{2}}\left(\bm{L}+\frac{\bm{I}_{q}}{\tau^{2}}\right).$$

Therefore, the $(1-\alpha)\times100\%$ confidence region for the potential terms over the posterior distribution, when $\sigma^2$ is estimated by $s^2$ on $\nu$ degrees of freedom, is given by \citep{Draper1998}:

$$(\bm{\beta}_{2}-\bm{b}_{2})^{'}(\bm{L}+\bm{I}_{q}/\tau^{2})(\bm{\beta}_{2}-\bm{b}_{2})\leq qs^{2}F_{q,\nu;1-\alpha},$$
where $\mathrm{F}(q,\nu,\alpha)$ is the $\alpha$-quantile of F-distribution with $q$ and $\nu$ degrees of freedom. Then, similarly, to $DP$-optimality, minimsing the volumeof this confidence region is equivalent to minimising $\left|\bm{L}+\frac{\bm{I}_{q}}{\tau^{2}}\right|^{-1/q}F_{q,d;1-\alpha_{LoF}}$. The matrix is directly related to the lack-of-fit component in the Generalised criteria developed by Goos et al. (2005) -- in case the error estimate does not depend on the design.

\subsection{MSE-based bias criterion}
From the inference point of view, in the case of potential model contamination the bias in the parameters' estimates would be of substantial interest. A natural way of evaluating the quality of $\bm{\hat{\beta}}_{1}$, as noted by \citet{FedorovMontepiedra1997} is the matrix of  mean square error, which is the $\bm{L}_2$-distance between the true and estimated values with respect to the probability distribution measure of $\bm{Y}$ under the assumption of model (\ref{eq::full_m}):
\begin{align}
\label{eq::MSE}
\mbox{MSE}(\bm{\hat{\beta}}_1|\bm{\beta})=&\mathtt{E}_{\bm{Y}|\bm{\beta}}[(\bm{\hat{\beta}}_1-\bm{\beta}_1)(\bm{\hat{\beta}}_1-\bm{\beta}_1)']\notag\\=&\sigma^2(\bm{X}_1^{'}\bm{X}_1)^{-1}+\bm{A}\bm{\beta}_2\bm{\beta}_2'\bm{A}', 
\end{align}
where, as before, $\bm{A}=(\bm{X}_1^{'}\bm{X}_1)^{-1}\bm{X}_1^{'}\bm{X}_2$ is the alias matrix.
The determinant-based criterion function is minimising
\begin{equation}
\label{eq::MSE_det}
\mathtt{E}_{\beta}\log(\det[\mbox{MSE}(\bm{\hat{\beta}}_1|\bm{\beta})]),
\end{equation}
where by $\bm{\beta}$ we denote the joint vector of primary and potential model parameters: $\bm{\beta}=[\bm{\beta}_1, \bm{\beta}_2]$.
Using the matrix determinant lemma \citep{Harville2006matrix}
\begin{equation*}
\det[\bm{P}+\bm{uv}']=\det[\bm{P}]\det[1+\bm{v'}\bm{P}^{-1}\bm{u}], 
\end{equation*}
where $\bm{P}$ is an invertible square matrix and $\bm{u}$, $\bm{v}$ are column vectors, the determinant in (\ref{eq::MSE_det}) can be decomposed:
\begin{align}
\label{eq::mse_det_dec}
&\det[\mbox{MSE}(\bm{\hat{\beta}}_1|\bm{\beta}_2)]\notag\\&=\det[\sigma^2\bm{M}^{-1}+\bm{M}^{-1}\bm{X}_1^{'}\bm{X}_2\bm{\beta}_2\bm{\beta}_2'\bm{X}_2^{'}\bm{X}_1\bm{M}^{-1}]\notag\\&=\sigma^{2p}\det[\bm{M}^{-1}+\bm{M}^{-1}\bm{X}_1^{'}\bm{X}_2\bm{\tilde{\beta}}_2\bm{\tilde{\beta}}_2'\bm{X}_2^{'}\bm{X}_1\bm{M}^{-1}]\notag\\&=\sigma^{2p}\det[\bm{M}^{-1}]\det[1+\bm{\tilde{\beta}}_2'\bm{X}_2^{'}\bm{X}_1\bm{M}^{-1}\bm{M}\bm{M}^{-1}\bm{X}_1^{'}\bm{X}_2\bm{\tilde{\beta}}_2]\notag\\&=\sigma^{2p}\det[\bm{M}^{-1}](1+\bm{\tilde{\beta}}_2'\bm{X}_2^{'}\bm{X}_1\bm{M}^{-1}\bm{X}_1^{'}\bm{X}_2\bm{\tilde{\beta}}_2),\\
&\mbox{where } \bm{M}=\bm{X}_1^{'}\bm{X}_1 \mbox{ and }\bm{\tilde{\beta}}_2=\bm{\beta}_2/\sigma. \notag
\end{align}
Applying the logarithm function gives us the following sum:
\begin{align*}
&\log(\det[\mbox{MSE}(\bm{\hat{\beta}}_1|\bm{\beta}_2)])\\&=p\log\sigma^2+\log(\det[\bm{M}^{-1}])+\log(1+\bm{\tilde{\beta}}_2'\bm{X}_2^{'}\bm{X}_1\bm{M}^{-1}\bm{X}_1^{'}\bm{X}_2\bm{\tilde{\beta}}_2). 
\end{align*}
The first summand does not depend on the design, so it will not be included in the criterion; the second one is the $D$-optimality component. Therefore, (\ref{eq::MSE_det}) is replaced by
\begin{equation*}
\log(\det[\bm{M}^{-1}])+\mathtt{E}_{\bm{\tilde{\beta}}_2}\log(1+\bm{\tilde{\beta}}_2'\bm{X}_2^{'}\bm{X}_1\bm{M}^{-1}\bm{X}_1^{'}\bm{X}_2\bm{\tilde{\beta}}_2).
\end{equation*}

The second term needs to be evaluated numerically due to the obvious lack of information regarding the potential terms' coefficients. Note that as $\bm{\beta}_2 \sim \mathcal{N}(\bm{0},\tau^{2}\sigma^{2}\bm{I}_{q})$, then $\bm{\tilde{\beta}}_2 \sim \mathcal{N}(\bm{0},\tau^{2}\bm{I}_{q})$ and its prior distribution does not depend on the unknown $\sigma^2$.

To sum up, the resulting criterion function comprising the $DP$-criterion and the $LoF(DP)$-component from the generalised $DP$-criterion as well as the MSE-based part, all brought to the scale of efficiencies, is
\begin{align}
\label{eq::MSE_D}
\mbox{minimise }&\left[\left|\bm{X}'_{1}\bm{X}_{1}\right|^{-1/p}F_{p,d;1-\alpha_{DP}}\right]^{\kappa_{DP}} \times \notag \\ &\left[\left|\bm{L}+\frac{\bm{I}_{q}}{\tau^{2}}\right|^{-1/q}F_{q,d;1-\alpha_{LoF}}\right]^{\kappa_{LoF}}\times \notag\\ & \left[|\bm{X}'_{1}\bm{X}_{1}|^{-1}\exp\left(\frac{1}{N}\sum_{i=1}^{N}\log(1+\bm{\tilde{\beta}}_{2i}'\bm{X}_2^{'}\bm{X}_1\bm{M}^{-1}\bm{X}_1^{'}\bm{X}_2\bm{\tilde{\beta}}_{2i})\right)\right]_{.}^{\kappa_{MSE}/p}
\end{align}
Here $\bm{\tilde{\beta}}_{2i}$, $i=1..N$ -- independent random vectors sampled from $\mathcal{N}(\bm{0},\tau^{2}\sigma^{2}\bm{I}_{q})$.

\subsubsection{Point-based estimate}
?? Should this Section be much shorter
One of the alternatives to the MC approach we would be willing to consider is to use the point prior for $\bm{\beta}_2$, that is $\bm{\beta}_2=\sigma\tau\bm{1}_q$ (where $\bm{1}_q$ is a $q$-dimensional vector with all components being equal to $1$), which is the standard deviation  of the initial (normal) prior. Therefore, $\bm{\tilde{\beta}}_2=\tau\bm{1}_q$, and the MSE(D)-part is
\begin{align*}
&|\bm{X}'_{1}\bm{X}_{1}|^{-1}(1+\bm{\tilde{\beta}}_{2}'\bm{X}_2^{'}\bm{X}_1\bm{M}^{-1}\bm{X}_1^{'}\bm{X}_2\bm{\tilde{\beta}}_{2})\\=&|\bm{X}'_{1}\bm{X}_{1}|^{-1}(1+\tau^2\bm{1}'_q\bm{X}_2^{'}\bm{X}_1\bm{M}^{-1}\bm{X}_1^{'}\bm{X}_2\bm{1}_q)\\=&|\bm{X}'_{1}\bm{X}_{1}|^{-1}\left(1+\tau^2\sum_{i,j=1}^{q}[\bm{X}_2^{'}\bm{X}_1\bm{M}^{-1}\bm{X}_1^{'}\bm{X}_2]_{(i,j)}\right),
\end{align*}
so essentially the last part of the equation is the summation of matrix elements, which obviously takes less computational time even for large dimensions $q$. 

The normal prior for $\bm{\beta}_2$ shall be preserved in the lack-of-fit component in (\ref{eq::MSE_D}), and so the criterion with the point prior estimate of the MSE(D)-component is the following function:
\begin{align}
\label{eq::MSE_D_point}
\mbox{minimise }&\left[\left|\bm{X}'_{1}\bm{X}_{1}\right|^{-1/p}F_{p,d;1-\alpha_{DP}}\right]^{\kappa_{DP}} \times \notag \\ &\left[\left|\bm{L}+\frac{\bm{I}_{q}}{\tau^{2}}\right|^{-1/q}F_{q,d;1-\alpha_{LoF}}\right]^{\kappa_{LoF}}\times \notag\\ & \left[|\bm{X}'_{1}\bm{X}_{1}|^{-1}\left(1+\tau^2\sum_{i,j=1}^{q}[\bm{X}_2^{'}\bm{X}_1\bm{M}^{-1}\bm{X}_1^{'}\bm{X}_2]_{(i,j)}\right)\right]_{.}^{\kappa_{MSE}/p}
\end{align}

Later we will refer to this as the ``MSE(D)P''-criterion, and in Section \ref{sec::mse_example} we will explore how much efficiency is lost when it is used instead of the computationally expensive original MSE(D)-based criterion (\ref{eq::MSE_D}).

To infer the trace-based form of the criterion, we use the pseudo-Bayesian approach to calculating the trace function of the MSE matrix (\ref{eq::MSE}): 
\begin{align*}
\mathtt{E}_{\beta_2}\mbox{trace}[\mbox{MSE}(\bm{\hat{\beta}}_1|\bm{\beta}_2)]&=\mbox{trace}[\mathtt{E}_{\beta_2}\mbox{MSE}(\bm{\hat{\beta}}_1|\bm{\beta}_2)]=\\&=\mbox{trace}[\sigma^2(\bm{X}_1^{'}\bm{X}_1)^{-1} + \mathtt{E}_{\bm{\beta}_2}(\bm{A}\bm{\beta}_2\bm{\beta}_2'\bm{A}')]=\\&=\mbox{trace}[\sigma^2(\bm{X}_1^{'}\bm{X}_1)^{-1}+\sigma^2\tau^2\bm{A}\bm{A}']=\\&=\sigma^2\mbox{trace}[(\bm{X}_1^{'}\bm{X}_1)^{-1}+\tau^2\bm{A}\bm{A}']\\&=\sigma^2[\mbox{trace}\{(\bm{X}_1^{'}\bm{X}_1)^{-1}\}+\tau^2\mbox{trace}\bm{A}\bm{A}'].
\end{align*}

The transitions above are possible due to commutativity of the operations of trace and expectation. The main advantage is the absence of the necessity of any additional numerical evaluations, and in this case of the trace-based criterion using the point prior for $\bm{\beta}_2$ defined earlier would lead to the same function. By minimising the whole function the sum of primary terms' variance and the expected squared norm of the bias vector in the direction of the potential terms are minimised simultaneously. The second part here contains the scaling parameter $\tau^2$ which regulates the magnitude of the potential terms' variation relatively to the error variance. 

Joining up the derived criterion function, the $LP$-criterion and the $LoF(LP)$-component from the generalised $LP$-criterion (\ref{eq::GLP_eff}), we obtain the compound criterion:
\begin{align}
\label{eq::MSE_L}
\mbox{minimise} &\left[\frac{1}{p}\mbox{trace}(\bm{WX}'_{1}\bm{X}_{1})^{-1}F_{1,d;1-\alpha_{LP}}\right]^{\kappa_{LP}}\times \notag\\& \left[\frac{1}{q}\mbox{trace}\left(\bm{L}+\frac{\bm{I}_{q}}{\tau^{2}}\right)^{-1}F_{1,d;1-\alpha_{LoF}}\right]^{\kappa_{LoF}}\times 
\notag\\& \left[\frac{1}{p}\mbox{trace}\{(\bm{X}'_{1}\bm{X}_{1})^{-1}+\tau^2\bm{A}\bm{A}'\}\right]^{\kappa_{MSE}}_{.}
\end{align}